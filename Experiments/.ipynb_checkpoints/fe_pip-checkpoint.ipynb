{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "07554153",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import string\n",
    "import pickle\n",
    "import textstat\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from langdetect import detect\n",
    "from spellchecker import SpellChecker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "0a4cfbf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US civil war causes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>scooter brands</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>scooter brands reliable</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>scooter</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>scooter cheap</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     query  class\n",
       "0      US civil war causes      0\n",
       "1           scooter brands      0\n",
       "2  scooter brands reliable      0\n",
       "3                  scooter      0\n",
       "4            scooter cheap      0"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AllQueries = pickle.load( open( \"data/AllQueries4746.p\", \"rb\" ) )\n",
    "AllQueries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "a9625186",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = AllQueries['query'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b0a912",
   "metadata": {},
   "source": [
    "##  allFeatures DataFrame\n",
    "\n",
    "Initiate a DataFrame to accumulate all features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "8653944e",
   "metadata": {},
   "outputs": [],
   "source": [
    "allFeatures = AllQueries.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb656871",
   "metadata": {},
   "source": [
    "## Spelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "baaddfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# oneOff=0\n",
    "# for can in list(spell.candidates('dg')):\n",
    "#     if can in list(spell.edit_distance_1('dg')):\n",
    "#         oneOff += 1\n",
    "#     break\n",
    "# oneOff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "c8e429ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spell.edit_distance_1('dg').intersection(spell.candidates('dg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d172d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "37821546",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spell.edit_distance_1('hre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "0e51b5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spell.candidates('hre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "3e830b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# name(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "048a1797",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Spelling(queries):\n",
    "    \n",
    "    wsle=pd.read_csv('data/KidSpell/Web_Search_Lab_Errors.csv',\n",
    "                usecols=['spelling']).spelling.tolist()\n",
    "    \n",
    "    wsie=pd.read_csv('data/KidSpell/Web_Search_Informal_Errors.csv',\n",
    "                usecols=['spelling']).spelling.tolist()\n",
    "    \n",
    "    ewe=pd.read_csv('data/KidSpell/Essay_Writing_Errors.csv',\n",
    "                usecols=['Spelling']).Spelling.tolist()\n",
    "    \n",
    "    kidsMispelled= set(wsle+wsie+ewe)\n",
    "    \n",
    "    spell = SpellChecker()\n",
    "    kidsError=[]\n",
    "    oneOffError = []\n",
    "    misspelledCol=[]\n",
    "    for i, query in enumerate(queries):\n",
    "\n",
    "        query=query.translate(str.maketrans('', '', string.punctuation)) # -- remove all panctuations\n",
    "\n",
    "        misspelled=spell.unknown(query.split()) \n",
    "\n",
    "        missed_k=misspelled.intersection(kidsMispelled)\n",
    "        kidsError.append(len(missed_k))\n",
    "        misspelledCol.append(len(misspelled))\n",
    "\n",
    "        oneOff = 0\n",
    "        try:\n",
    "            for word in misspelled:\n",
    "                mis_one=spell.edit_distance_1(word).\\\n",
    "                intersection(spell.candidates(word))\n",
    "\n",
    "                if len(mis_one) > 0:\n",
    "                    oneOff+=1\n",
    "            oneOffError.append(oneOff)\n",
    "\n",
    "        except:\n",
    "            oneOffError.append(-1)\n",
    "\n",
    "    #     if len(missed_k) != 0:\n",
    "    #         print(i, len(missed_k), missed_k)\n",
    "        #print(len(misspelled.intersection(kidsMispelled)))\n",
    "        #print(misspelled)\n",
    "        \n",
    "    allFeatures=(\n",
    "        allFeatures\n",
    "        .assign(kidsError=kidsError)\n",
    "        .assign(misspelledCol=misspelledCol)\n",
    "        .assign(oneOffError=oneOffError)\n",
    "    )\n",
    "#     print(allFeatures)\n",
    "    \n",
    "    return allFeatures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "4b204e72",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'allFeatures' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-229-102fbb7cedf7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mSpelling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-228-e3af2b72709e>\u001b[0m in \u001b[0;36mSpelling\u001b[0;34m(queries)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     allFeatures=(\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mallFeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkidsError\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkidsError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmisspelledCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmisspelledCol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'allFeatures' referenced before assignment"
     ]
    }
   ],
   "source": [
    "Spelling(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8d6b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spell = SpellChecker()\n",
    "# kidsError=[]\n",
    "# oneOffError = []\n",
    "# misspelledCol=[]\n",
    "# for i, query in enumerate(queries):\n",
    "    \n",
    "#     query=query.translate(str.maketrans('', '', string.punctuation)) # -- remove all panctuations\n",
    "    \n",
    "#     misspelled=spell.unknown(query.split()) \n",
    "    \n",
    "#     missed_k=misspelled.intersection(kidsMispelled)\n",
    "#     kidsError.append(len(missed_k))\n",
    "#     misspelledCol.append(len(misspelled))\n",
    "    \n",
    "#     oneOff = 0\n",
    "#     try:\n",
    "#         for word in misspelled:\n",
    "#             mis_one=spell.edit_distance_1(word).\\\n",
    "#             intersection(spell.candidates(word))\n",
    "            \n",
    "#             if len(mis_one) > 0:\n",
    "#                 oneOff+=1\n",
    "#         oneOffError.append(oneOff)\n",
    "                \n",
    "#     except:\n",
    "#         oneOffError.append(-1)\n",
    "        \n",
    "# #     if len(missed_k) != 0:\n",
    "# #         print(i, len(missed_k), missed_k)\n",
    "#     #print(len(misspelled.intersection(kidsMispelled)))\n",
    "    \n",
    "    \n",
    "    \n",
    "#     #print(misspelled)\n",
    "# allFeatures=(\n",
    "#     allFeatures\n",
    "#     .assign(kidsError=kidsError)\n",
    "#     .assign(misspelledCol=misspelledCol)\n",
    "#     .assign(oneOffError=oneOffError)\n",
    "# ).head(10)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4248af07",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(spell.unknown('I live in Nwe Yokr'.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed61651b",
   "metadata": {},
   "outputs": [],
   "source": [
    "j={'dribiling', 'dring', 'Yokr'}\n",
    "len(j.intersection(kidsMispelled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "9744cf45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{nan,\n",
       " 'ese',\n",
       " 'dribiling',\n",
       " 'duscoverd',\n",
       " 'dring',\n",
       " 'mi',\n",
       " 'chude',\n",
       " 'pooring',\n",
       " 'huging',\n",
       " 'comperyhention',\n",
       " 'silc',\n",
       " 'dolfen',\n",
       " 'fot',\n",
       " 'makeing',\n",
       " 'way',\n",
       " 'so',\n",
       " 'stoveris',\n",
       " 'armer',\n",
       " 'cryed',\n",
       " 'putatos',\n",
       " 'choclete',\n",
       " 'choaclet',\n",
       " 'fivret',\n",
       " 'varey',\n",
       " 'ovoyd',\n",
       " 'cudly',\n",
       " 'smel',\n",
       " 'soseg',\n",
       " 'miyols',\n",
       " 'scientact',\n",
       " 'tarnamint',\n",
       " 'litel',\n",
       " 'othe',\n",
       " 'woulb',\n",
       " 'desiner',\n",
       " 'nasttek',\n",
       " 'pishis',\n",
       " 'eveything',\n",
       " 'dg',\n",
       " 'nastteks',\n",
       " 'smels',\n",
       " 'snacke',\n",
       " 'crard',\n",
       " 'beick',\n",
       " 'peple',\n",
       " 'faerl',\n",
       " 'neks',\n",
       " 'whith',\n",
       " 'cosen',\n",
       " 'lemen',\n",
       " 'gim',\n",
       " \"dosen't\",\n",
       " 'grand',\n",
       " 'cood',\n",
       " 'planit',\n",
       " 'rids',\n",
       " 'riped',\n",
       " 'cut',\n",
       " 'bater ',\n",
       " 'kice',\n",
       " 'writeing',\n",
       " 'snc',\n",
       " 'travelling',\n",
       " 'know',\n",
       " 'eliffent',\n",
       " 'weard',\n",
       " 'up stars',\n",
       " 'favrite',\n",
       " 'sowed',\n",
       " 'upcomeing',\n",
       " 'cewed',\n",
       " 'ges',\n",
       " 'comen',\n",
       " 'scientce',\n",
       " 'hog',\n",
       " 'your',\n",
       " 'balt',\n",
       " 'anamal',\n",
       " 'swiming',\n",
       " 'cumpiter',\n",
       " 'stiek',\n",
       " 'cheescake',\n",
       " 'wepin',\n",
       " 'tastes',\n",
       " 'bicas',\n",
       " 'sam',\n",
       " 'thas',\n",
       " 'wate',\n",
       " 'apon',\n",
       " 'fortunit',\n",
       " 'colerful',\n",
       " 'becaus',\n",
       " 'sed',\n",
       " 'brater',\n",
       " 'stintist',\n",
       " \"Luige's\",\n",
       " 'blod',\n",
       " 'rely',\n",
       " 'fead',\n",
       " 'unecorn',\n",
       " 'hed',\n",
       " 'holl',\n",
       " 'joks',\n",
       " 'yare',\n",
       " 'stars',\n",
       " 'btit',\n",
       " 'frum',\n",
       " 'cak',\n",
       " 'chokelet',\n",
       " 'da',\n",
       " 'coll',\n",
       " 'pistile',\n",
       " 'perogeram',\n",
       " 'fiyor',\n",
       " 'paril',\n",
       " 'husche',\n",
       " 'fregot',\n",
       " 'cleank',\n",
       " 'rood',\n",
       " 'sqirt',\n",
       " 'sulfer',\n",
       " 'copeter',\n",
       " 'win',\n",
       " 'being',\n",
       " 'hangre',\n",
       " 'stad',\n",
       " 'chec',\n",
       " 'thaer',\n",
       " 'intrdoos',\n",
       " 'vary',\n",
       " 'mountian',\n",
       " 'egale',\n",
       " 'won',\n",
       " 'gowen',\n",
       " 'famelli',\n",
       " 'vacashin',\n",
       " 'mushean',\n",
       " 'deth',\n",
       " 'hospitole',\n",
       " 'animole',\n",
       " 'faks',\n",
       " 'erath',\n",
       " 'wok',\n",
       " 'rum',\n",
       " 'dans',\n",
       " 'chapinship',\n",
       " 'amoe',\n",
       " 'Texes',\n",
       " 'custome',\n",
       " 'muki',\n",
       " 'grabed',\n",
       " 'evething',\n",
       " 'incretibal',\n",
       " 'rideing',\n",
       " 'perfermer',\n",
       " 'taseted',\n",
       " 'grem',\n",
       " 'wh',\n",
       " 'sefe',\n",
       " 'monky',\n",
       " 'abowt',\n",
       " 'heer',\n",
       " 'spicific',\n",
       " 'shautd',\n",
       " 'clasrums',\n",
       " 'coms',\n",
       " 'upstars',\n",
       " 'adawt',\n",
       " 'dolfin',\n",
       " 'numbr',\n",
       " 'wode',\n",
       " 'culers',\n",
       " 'stumick',\n",
       " 'thar',\n",
       " 'clamed',\n",
       " 'boke',\n",
       " 'crazzy',\n",
       " 'hoomadrobots',\n",
       " 'concer',\n",
       " 'oniens',\n",
       " 'choclat',\n",
       " 'here',\n",
       " 'summery',\n",
       " 'korts',\n",
       " 'gloff',\n",
       " 'qustions',\n",
       " 'costum',\n",
       " 'difrint',\n",
       " 'climed',\n",
       " 'labron',\n",
       " 'mised',\n",
       " 'ginn',\n",
       " 'cadig',\n",
       " 'campling',\n",
       " 'pla',\n",
       " 'cin',\n",
       " 'hemeyoc',\n",
       " 'fierst',\n",
       " 'chincin',\n",
       " 'stiripes',\n",
       " 'probly',\n",
       " 'sek',\n",
       " 'gos',\n",
       " 'peperone',\n",
       " 'peapl',\n",
       " 'kide',\n",
       " 'famos',\n",
       " 'coopon',\n",
       " 'freat',\n",
       " 'controled',\n",
       " 'everwone',\n",
       " 'sincerly',\n",
       " 'cukee',\n",
       " 'tichor',\n",
       " 'cot',\n",
       " 'rodot',\n",
       " 'ston',\n",
       " 'wat',\n",
       " 'steem',\n",
       " 'cpuder',\n",
       " 'compoused',\n",
       " 'looket',\n",
       " 'gevs',\n",
       " 'wus',\n",
       " 'rlrcsts',\n",
       " 'seid',\n",
       " 'frends',\n",
       " 'sodrday',\n",
       " 'care',\n",
       " 'gose',\n",
       " 'though',\n",
       " 'rete',\n",
       " 'peepoll',\n",
       " 'inchrodoost',\n",
       " 'skard',\n",
       " 'sem',\n",
       " 'aellien',\n",
       " 'fiteing',\n",
       " 'neighboors',\n",
       " 'minits',\n",
       " 'kug',\n",
       " 'surching',\n",
       " 'dont',\n",
       " 'schoal',\n",
       " 'hamr',\n",
       " 'ups stars',\n",
       " 'aproprit',\n",
       " 'thot',\n",
       " 'wichis',\n",
       " 'fcts',\n",
       " 'responponsible',\n",
       " 'chickin',\n",
       " 'ded',\n",
       " 'whnt',\n",
       " 'beacuse',\n",
       " 'welf wof',\n",
       " 'liweegees',\n",
       " 'yus',\n",
       " 'figer',\n",
       " 'fer',\n",
       " 'juping',\n",
       " 'ave',\n",
       " 'villajg',\n",
       " 'chinkin',\n",
       " 'cip',\n",
       " 'robo',\n",
       " 'jerny',\n",
       " 'waerled',\n",
       " 'evrewan',\n",
       " 'peise',\n",
       " 'modas',\n",
       " 'a pone',\n",
       " 'hapened',\n",
       " 'som',\n",
       " 'maks',\n",
       " 'loded',\n",
       " 'fowned',\n",
       " 'plai',\n",
       " 'fite',\n",
       " 'peik',\n",
       " 'taset',\n",
       " 'becus',\n",
       " 'watever',\n",
       " 'skreming',\n",
       " 'Jonsun',\n",
       " 'tat',\n",
       " 'prite',\n",
       " 'dasen',\n",
       " 'Lackrs',\n",
       " 'cicin',\n",
       " 'cousens',\n",
       " 'yowst',\n",
       " 'shi',\n",
       " 'goe',\n",
       " 'ubout',\n",
       " 'anmls',\n",
       " 'lest',\n",
       " 'cold',\n",
       " 'choise',\n",
       " 'smoak',\n",
       " 'showes',\n",
       " 'billbord',\n",
       " 'rowned',\n",
       " 'casis',\n",
       " 'oreng',\n",
       " 'wood',\n",
       " 'fruty',\n",
       " 'wunt',\n",
       " 'step',\n",
       " 'shoo',\n",
       " 'tasit',\n",
       " 'muole',\n",
       " 'ining',\n",
       " 'dunot',\n",
       " 'stor',\n",
       " 'es',\n",
       " 'okword',\n",
       " 'af',\n",
       " 'slied',\n",
       " 'aetn',\n",
       " 'rictengal',\n",
       " 'portections',\n",
       " 'pickture',\n",
       " 'leving',\n",
       " 'pots',\n",
       " 'lien',\n",
       " 'wen',\n",
       " 'wit',\n",
       " 'may',\n",
       " 'mous',\n",
       " 'farst',\n",
       " 'tortch',\n",
       " 'sqeke',\n",
       " 'whants',\n",
       " 'safty',\n",
       " 'dume',\n",
       " 'supor',\n",
       " 'gofrend',\n",
       " 'bout',\n",
       " 'hontid',\n",
       " 'wolde',\n",
       " 'moch',\n",
       " \"din't\",\n",
       " 'storme',\n",
       " 'madeb',\n",
       " 'but',\n",
       " 'fote',\n",
       " 'cnput',\n",
       " 'relly',\n",
       " 'stek',\n",
       " 'tcholl',\n",
       " 'frice',\n",
       " 'robbsoij',\n",
       " 'frite',\n",
       " 'chard',\n",
       " 'silkey',\n",
       " 'mene',\n",
       " 'prgramr',\n",
       " 'shrk',\n",
       " 'scincetist',\n",
       " 'mi ',\n",
       " 'sleded',\n",
       " 'caching',\n",
       " 'wana',\n",
       " 'si',\n",
       " 'ro',\n",
       " 'soop',\n",
       " 'oder',\n",
       " 'trys',\n",
       " 'hows',\n",
       " 'alectrek',\n",
       " 'scentist',\n",
       " 'rad',\n",
       " 'choowing',\n",
       " 'exsmstopm',\n",
       " 'fortunite',\n",
       " 'iterresting',\n",
       " 'chokolet',\n",
       " 'magickl',\n",
       " 'vesets',\n",
       " 'tok',\n",
       " 'faca',\n",
       " 'one',\n",
       " 'fol',\n",
       " 'ove',\n",
       " 'frunt',\n",
       " 'tasts',\n",
       " 'bateroosh',\n",
       " 'oshan',\n",
       " 'and',\n",
       " 'mountans',\n",
       " 'sof',\n",
       " 'ilashes',\n",
       " 'ticher',\n",
       " 'brock',\n",
       " 'scorpeon',\n",
       " 'wint',\n",
       " 'explosin',\n",
       " 'olwas',\n",
       " 'flufe',\n",
       " 'plastik',\n",
       " 'spacecrafe',\n",
       " 'lian',\n",
       " 'scientace',\n",
       " 'vid',\n",
       " 'sliped',\n",
       " 'reses',\n",
       " 'lowed',\n",
       " 'cercus',\n",
       " 'yumy',\n",
       " 'abaout',\n",
       " 'lisan',\n",
       " 'bumbolbee',\n",
       " 'wot',\n",
       " 'poot',\n",
       " 'frenz',\n",
       " 'chrch',\n",
       " 'nois',\n",
       " 'jus',\n",
       " 'progeramer',\n",
       " 'war',\n",
       " 'sester',\n",
       " 'fand',\n",
       " 'caock',\n",
       " 'perpol',\n",
       " 'hundrid',\n",
       " 'stike',\n",
       " 'hole',\n",
       " 'tast',\n",
       " 'trampolene',\n",
       " 'quistins',\n",
       " 'spel',\n",
       " 'dilishes',\n",
       " 'scientac',\n",
       " 'oridi',\n",
       " 'sneack',\n",
       " 'sum thing',\n",
       " 'woched',\n",
       " 'bred',\n",
       " 'chees',\n",
       " 'brothe',\n",
       " 'fleep',\n",
       " 'landid',\n",
       " 'throgh',\n",
       " 'battleing',\n",
       " 'frist',\n",
       " 'bne',\n",
       " 'furtionet',\n",
       " 'lite',\n",
       " 'plo',\n",
       " 'tedye',\n",
       " 'how',\n",
       " 'hom',\n",
       " 'happly',\n",
       " 'feger',\n",
       " 'thier',\n",
       " 'fram',\n",
       " 'focx',\n",
       " 'kep',\n",
       " 'raning',\n",
       " 'sugry',\n",
       " 'agen',\n",
       " 'hotit',\n",
       " 'squair',\n",
       " 'solt',\n",
       " 'barls',\n",
       " 'explist',\n",
       " 'sratch',\n",
       " 'stude',\n",
       " 'vapirs',\n",
       " 'pitchers',\n",
       " 'prity',\n",
       " 'skwish',\n",
       " 'whoud',\n",
       " 'bu',\n",
       " 'mor',\n",
       " 'travling',\n",
       " 'folow',\n",
       " 'desine',\n",
       " 'or',\n",
       " 'alwase',\n",
       " 'slipt',\n",
       " 'cooice',\n",
       " 'nighte',\n",
       " 'rand',\n",
       " 'ferist',\n",
       " 'be case',\n",
       " 'techology',\n",
       " 'sad',\n",
       " 'takeing',\n",
       " 'somwan',\n",
       " 'desendens',\n",
       " 'drot',\n",
       " 'whereing',\n",
       " 'prepol',\n",
       " 'wofol',\n",
       " 'gras',\n",
       " 'oll',\n",
       " 'scrind',\n",
       " 'becuse',\n",
       " 'flours',\n",
       " 'onece',\n",
       " 'repe',\n",
       " 'colest',\n",
       " 'eletric',\n",
       " 'beg',\n",
       " 'donis',\n",
       " 'labartory',\n",
       " 'redy',\n",
       " \"sh'll\",\n",
       " 'slead',\n",
       " 'choclit',\n",
       " 'spoyel',\n",
       " 'utack',\n",
       " 'rote',\n",
       " 'facks',\n",
       " 'anser',\n",
       " 'sot',\n",
       " 'mammles',\n",
       " 'entr',\n",
       " 'eey',\n",
       " 'punat butter',\n",
       " 'ocen',\n",
       " 'shud',\n",
       " 'bubll',\n",
       " 'waned',\n",
       " 'spieck',\n",
       " 'lac',\n",
       " 'rid ',\n",
       " 'cian',\n",
       " 'summor',\n",
       " 'bananus',\n",
       " 'mean',\n",
       " 'cruncing',\n",
       " 'cum',\n",
       " 'maos',\n",
       " 'intristing',\n",
       " 'wors',\n",
       " 'macanical',\n",
       " 'sipl',\n",
       " 'difrent',\n",
       " 'becuum',\n",
       " 'inplisit',\n",
       " 'leared',\n",
       " 'sow',\n",
       " 'jamse',\n",
       " 'herd',\n",
       " 'enistein',\n",
       " 'anamol',\n",
       " 'now',\n",
       " 'whos',\n",
       " 'libron',\n",
       " 'jest',\n",
       " 'nexst',\n",
       " 'mete',\n",
       " 'frift',\n",
       " 'famis',\n",
       " 'blud',\n",
       " 'tit',\n",
       " 'git',\n",
       " 'chocroch',\n",
       " 'lokrs',\n",
       " 'a lout',\n",
       " 'enyware',\n",
       " 'vidio',\n",
       " 'bekus',\n",
       " 'grate',\n",
       " 'oners',\n",
       " 'optmi',\n",
       " 'favtit',\n",
       " 'catched',\n",
       " 'tipet',\n",
       " \"did't\",\n",
       " 'peroger',\n",
       " 'gams',\n",
       " 'snekt',\n",
       " 'scard',\n",
       " 'robet',\n",
       " 'cheeg',\n",
       " 'mad',\n",
       " 'fameo',\n",
       " 'sos',\n",
       " 'dreme',\n",
       " 'toger',\n",
       " 'beposios',\n",
       " 'funnyest',\n",
       " 'spaseship',\n",
       " 'refridgeorator',\n",
       " 'horrer',\n",
       " 'frst',\n",
       " 'cach',\n",
       " 'smoth',\n",
       " 'stell',\n",
       " 'sownd',\n",
       " 'pratis',\n",
       " 'pigens',\n",
       " 'mowth',\n",
       " 'smald',\n",
       " 'blu',\n",
       " 'ther',\n",
       " 'prpl',\n",
       " 'confidind',\n",
       " 'hase',\n",
       " 'ticettes',\n",
       " 'stroung',\n",
       " 'ranck',\n",
       " 'gust',\n",
       " 'mak',\n",
       " 'verchrl',\n",
       " 'xspladed',\n",
       " 'quikly',\n",
       " 'infinit',\n",
       " 'crasy',\n",
       " 'egs',\n",
       " 'raisan',\n",
       " 'loot',\n",
       " 'texes',\n",
       " 'posin',\n",
       " 'pare',\n",
       " 'charg',\n",
       " 'og',\n",
       " 'gut',\n",
       " 'suter',\n",
       " 'butery',\n",
       " 'waerd',\n",
       " 'flay',\n",
       " 'glas',\n",
       " 'mansiuon',\n",
       " 'seting',\n",
       " 'shewy',\n",
       " 'dun',\n",
       " 'bikse',\n",
       " 'trid',\n",
       " 'ive',\n",
       " 'gam',\n",
       " 'watir',\n",
       " 'marbols',\n",
       " 'burs',\n",
       " 'dident',\n",
       " 'choclet',\n",
       " 'ple',\n",
       " 'train',\n",
       " 'bie',\n",
       " 'sode',\n",
       " 'wildernis',\n",
       " 'bel',\n",
       " 'loking',\n",
       " 'chese',\n",
       " 'stadeum',\n",
       " 'favrit',\n",
       " 'stof',\n",
       " 'befor',\n",
       " 'flawer',\n",
       " 'ech',\n",
       " 'tedeeber',\n",
       " 'giroff',\n",
       " 'creat',\n",
       " 'wokt',\n",
       " 'beter',\n",
       " 'thout',\n",
       " 'puncht',\n",
       " 'plases',\n",
       " 'revisen',\n",
       " 'whay',\n",
       " 'be',\n",
       " 'day',\n",
       " 'forst',\n",
       " 'interestinf',\n",
       " 'suddently',\n",
       " 'namd',\n",
       " 'carit',\n",
       " 'rit',\n",
       " 'axed',\n",
       " 'beal',\n",
       " 'intell',\n",
       " 'groud',\n",
       " 'hols',\n",
       " 'hous',\n",
       " 'woking',\n",
       " 'spiting',\n",
       " 'riad',\n",
       " 'tings',\n",
       " 'somple',\n",
       " 'pagis',\n",
       " 'gow',\n",
       " 'therd',\n",
       " 'acurit',\n",
       " 'botel',\n",
       " 'rian',\n",
       " 'dallfin',\n",
       " 'dit',\n",
       " 'breevu',\n",
       " 'redea',\n",
       " 'tride',\n",
       " 'stending',\n",
       " 'nam',\n",
       " 'fond',\n",
       " 'cors',\n",
       " 'wr',\n",
       " 'samtams',\n",
       " 'men',\n",
       " 'flut',\n",
       " 'soot',\n",
       " 'plas',\n",
       " 'waet',\n",
       " 'programer',\n",
       " 'hav',\n",
       " 'hiting',\n",
       " 'fel',\n",
       " 'very',\n",
       " 'inventi',\n",
       " 'mufin',\n",
       " 'sleed',\n",
       " 'lif',\n",
       " 'en',\n",
       " 'lwebron',\n",
       " 'sower',\n",
       " 'softe',\n",
       " 'sqweeking',\n",
       " 'valcano',\n",
       " 'nuw',\n",
       " 'vido',\n",
       " 'strit',\n",
       " 'skreem',\n",
       " 'mack',\n",
       " 'trened',\n",
       " 'itz',\n",
       " 'marckr',\n",
       " 'bat',\n",
       " 'solty',\n",
       " 'luky',\n",
       " 'samon',\n",
       " 'midul',\n",
       " 'brite',\n",
       " 'dctor',\n",
       " 'explanstopm',\n",
       " 'tietts',\n",
       " 'eseay',\n",
       " 'wont',\n",
       " 'sentenses',\n",
       " 'cheses',\n",
       " 'gymnasteks',\n",
       " 'eta',\n",
       " 'crecher',\n",
       " 'tempechers',\n",
       " 'frirends',\n",
       " 'yoos',\n",
       " 'stick',\n",
       " 'fil',\n",
       " 'haos',\n",
       " 'informs',\n",
       " 'fether',\n",
       " 'coces',\n",
       " 'evr',\n",
       " 'favurite',\n",
       " 'beech',\n",
       " 'cen',\n",
       " 'docter',\n",
       " 'cand',\n",
       " 'chimne',\n",
       " 'techden',\n",
       " 'hir',\n",
       " 'hapy',\n",
       " 'howse',\n",
       " 'bicos',\n",
       " 'mat',\n",
       " 'robi',\n",
       " 'haded',\n",
       " 'adventur',\n",
       " 'magick',\n",
       " 'aftr',\n",
       " 'ferstcopet',\n",
       " 'evry',\n",
       " 'feard',\n",
       " 'becas ',\n",
       " 'copet',\n",
       " 'glave',\n",
       " 'famoly',\n",
       " 'therecer',\n",
       " 'wuod',\n",
       " 'tetcnoglye',\n",
       " 'tha',\n",
       " 'codd',\n",
       " 'preform',\n",
       " 'sherching',\n",
       " 'likrorish',\n",
       " 'for evr',\n",
       " 'csim',\n",
       " 'scraches',\n",
       " 'thes',\n",
       " 'fownd',\n",
       " 'dres',\n",
       " 'becas',\n",
       " 'to',\n",
       " 'boll',\n",
       " 'gou',\n",
       " 'werd',\n",
       " 'buteful',\n",
       " 'wer',\n",
       " 'nids',\n",
       " 'my',\n",
       " 'spead',\n",
       " 'mose',\n",
       " 'sivilise',\n",
       " 'camoflage',\n",
       " 'kiks',\n",
       " 'bother',\n",
       " 'recshed',\n",
       " 'lolipop',\n",
       " 'thousen',\n",
       " 'cumpudr',\n",
       " 'scientitst',\n",
       " 'caming',\n",
       " 'frait',\n",
       " 'seads',\n",
       " 'liek',\n",
       " 'priins',\n",
       " 'sucsses',\n",
       " 'librareay',\n",
       " 'optmis',\n",
       " 'mounth',\n",
       " 'firends',\n",
       " 'oun',\n",
       " 'frins',\n",
       " 'bae',\n",
       " 'lick',\n",
       " 'stichs',\n",
       " 'bookmrc',\n",
       " 'evented',\n",
       " 'robat',\n",
       " 'ferst',\n",
       " 'sors',\n",
       " 'frenly',\n",
       " 'fiered',\n",
       " 'fes',\n",
       " 'pergamer',\n",
       " 'leps',\n",
       " 'thir',\n",
       " 'programes',\n",
       " 'evrey',\n",
       " 'exept',\n",
       " 'gay',\n",
       " 'butyfol',\n",
       " 'wheal',\n",
       " 'journel',\n",
       " 'wold',\n",
       " 'furgot',\n",
       " 'flote',\n",
       " 'cathing',\n",
       " 'pople',\n",
       " 'caput',\n",
       " 'versons',\n",
       " 'tiy',\n",
       " 'marvills',\n",
       " 'chanch',\n",
       " 'bak',\n",
       " 'climd',\n",
       " 'hop',\n",
       " 'cuf av',\n",
       " 'anolying',\n",
       " 'gugl',\n",
       " 'meen',\n",
       " 'crad',\n",
       " 'wheth',\n",
       " 'trane',\n",
       " 'faviort',\n",
       " 'swin',\n",
       " 'rases',\n",
       " 'moove',\n",
       " 'asome',\n",
       " 'alow',\n",
       " 'dackpack',\n",
       " 'chayses',\n",
       " 'mirr',\n",
       " 'bot',\n",
       " 'gluve',\n",
       " 'fas',\n",
       " 'gat',\n",
       " 'univeres',\n",
       " 'coud',\n",
       " 'sweap',\n",
       " 'robos',\n",
       " 'bekame',\n",
       " 'bady',\n",
       " 'trecotriding',\n",
       " 'allot',\n",
       " 'girel',\n",
       " 'tonit',\n",
       " 'swors',\n",
       " 'wiht',\n",
       " 'yer',\n",
       " 'agenst',\n",
       " 'elefant',\n",
       " 'wut',\n",
       " 'skream',\n",
       " 'plase',\n",
       " 'dolr',\n",
       " 'thy',\n",
       " 'than',\n",
       " 'langu',\n",
       " 'teri',\n",
       " 'exsited',\n",
       " 'frenid',\n",
       " 'kik',\n",
       " 'souds',\n",
       " 'opsticol',\n",
       " 'set',\n",
       " 'ckudly',\n",
       " 'crassy',\n",
       " 'traped',\n",
       " 'Rodo',\n",
       " 'scoot',\n",
       " 'evirthing',\n",
       " 'dose',\n",
       " 'fiting',\n",
       " 'hrt',\n",
       " 'whater',\n",
       " 'poping',\n",
       " 'fortunet',\n",
       " 'chicen',\n",
       " 'dolfins',\n",
       " 'pictur',\n",
       " 'wand',\n",
       " 'boiesechools',\n",
       " 'uv',\n",
       " 'deach',\n",
       " 'whant',\n",
       " 'remeber',\n",
       " 'woching',\n",
       " 'tryed',\n",
       " 'kindirgartin',\n",
       " 'hikeing',\n",
       " 'sayler',\n",
       " 'cald',\n",
       " 'riag',\n",
       " 'halewen',\n",
       " 'gunn',\n",
       " 'gound',\n",
       " 'lik',\n",
       " 'brot',\n",
       " 'gils',\n",
       " 'avery',\n",
       " 'scool',\n",
       " 'donats',\n",
       " 'sid',\n",
       " 'prsan',\n",
       " 'tokeg',\n",
       " 'beinning',\n",
       " 'tim',\n",
       " 'hirow',\n",
       " 'skiterles',\n",
       " 'frind',\n",
       " 'ware',\n",
       " 'fune',\n",
       " 'wonderd',\n",
       " \"Luigie's\",\n",
       " 'pupee',\n",
       " 'tam',\n",
       " 'ice crem',\n",
       " 'whore',\n",
       " 'mamils',\n",
       " 'calrful',\n",
       " 'thougt',\n",
       " 'dech',\n",
       " 'anether',\n",
       " 'facs',\n",
       " 'revord',\n",
       " 'octmis',\n",
       " 'geting',\n",
       " 'abat',\n",
       " 'ran ',\n",
       " 'tomato',\n",
       " 'meet',\n",
       " 'wonld',\n",
       " 'cam',\n",
       " 'thay',\n",
       " 'siting',\n",
       " 'inventid',\n",
       " 'sum',\n",
       " 'runing',\n",
       " 'hoo',\n",
       " 'Halleween',\n",
       " 'trieing',\n",
       " 'wrms',\n",
       " 'explstopm',\n",
       " 'tokes',\n",
       " 'slep',\n",
       " 'scaches',\n",
       " 'tectnogly',\n",
       " 'du',\n",
       " 'evended',\n",
       " 'clas',\n",
       " 'wod',\n",
       " 'littol',\n",
       " 'programmr',\n",
       " 'wy',\n",
       " 'Haloween',\n",
       " 'scorpen',\n",
       " 'goeto',\n",
       " 'trafik',\n",
       " ...}"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kidsMispelled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "d6718e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def Spelling(queriesList):\n",
    "    \n",
    "# #     setQueries = df['query'].tolist()\n",
    "    \n",
    "#     wsle=pd.read_csv('data/KidSpell/Web_Search_Lab_Errors.csv',\n",
    "#                 usecols=['spelling']).spelling.tolist()\n",
    "    \n",
    "#     wsie=pd.read_csv('data/KidSpell/Web_Search_Informal_Errors.csv',\n",
    "#                 usecols=['spelling']).spelling.tolist()\n",
    "    \n",
    "#     ewe=pd.read_csv('data/KidSpell/Essay_Writing_Errors.csv',\n",
    "#                 usecols=['Spelling']).Spelling.tolist()\n",
    "    \n",
    "#     kidsMispelled= set(wsle+wsie+ewe)\n",
    "    \n",
    "# #--------------------------------------------------------------------------------\n",
    "\n",
    "#     spell = SpellChecker()\n",
    "#     spellingError = []\n",
    "#     oneOffError = []\n",
    "#     kidsError = []\n",
    "#     misspelledCol = []\n",
    "\n",
    "#     netModifiers = ['www', 'http', '.com', '.net', '.edu', '.org', '.gov', '.co', '.mil', '.com']\n",
    "\n",
    "#     with tqdm(total = len(queries) ) as pbar:\n",
    "#         for query in queries:\n",
    "#             query =  query.translate(str.maketrans('', '', string.punctuation)) # -- remove all panctuations\n",
    "#             website = [mod for mod in netModifiers if(mod in query)] # --- save the netModifiers in the queries\n",
    "#             if not website:\n",
    "#                 misspelledWords = \"\";\n",
    "#                 try:\n",
    "#                     lang = detect(query) # -- detects a language \n",
    "#                     misspelled = spell.unknown(query.split(\" \")) # -- unknown gives the misspelled words\n",
    "#                     found = 0\n",
    "#                     oneOff = 0\n",
    "#                     kidsMis = 0\n",
    "#                     for word in misspelled:\n",
    "#                         misspelledWords += \", \" + word # -- concatinating the misspelled words\n",
    "#                         if word in kidsMispelled:\n",
    "#                             kidsMis +=1\n",
    "#                         candid = spell.candidates(word) # candidates() displays the set of words that are close to the word entered\n",
    "#     #                     print(candid)\n",
    "#     #                     print(\"-------start edits-----------------\")\n",
    "#                         edits = spell.edit_distance_1(word)\n",
    "#     #                     print(edits)\n",
    "#     #                     print(\"-----------end edits-------------\")\n",
    "\n",
    "#                         for can in candid:\n",
    "#                             if can in edits:\n",
    "#                                 oneOff += 1\n",
    "#                             break\n",
    "#     #                     print(word +' Out')\n",
    "#                     oneOffError.append(oneOff)\n",
    "#                     spellingError.append(len(misspelled))\n",
    "#                     kidsError.append(kidsMis)\n",
    "#     #                 misspelledCol.append(misspelledWords)\n",
    "\n",
    "#                 except:\n",
    "#     #                 print(misspelled)\n",
    "#                     oneOffError.append(-1)\n",
    "#                     spellingError.append(-1)\n",
    "#                     kidsError.append(-1)\n",
    "#     #                 misspelledCol.append(misspelledWords)\n",
    "\n",
    "#             else:\n",
    "#                 spellingError.append(0)\n",
    "#                 oneOffError.append(0)\n",
    "#                 kidsError.append(0)\n",
    "\n",
    "#             pbar.update()\n",
    "\n",
    "#     spelling = pd.DataFrame(data=spellingError, columns = ['numSpellingErrors'])\n",
    "#     spelling['query'] = queries\n",
    "#     spelling['offByOne'] = oneOffError\n",
    "#     spelling['kidsError'] = kidsError\n",
    "\n",
    "\n",
    "\n",
    "# # ----------------------------------------------------------------------------\n",
    "    \n",
    "#     return spelling\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bdaf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = Spelling(queries)\n",
    "# a.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b8021e",
   "metadata": {},
   "source": [
    "## Punct and Casing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "7afe9f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Punct_Spell(query_list):\n",
    "    invalidcharacters= set(['!', ',', '.', '?'])\n",
    "    punct = []\n",
    "    casing = []\n",
    "    with tqdm(total = len(queries) ) as pbar:\n",
    "        for query in queries:\n",
    "\n",
    "            if any(char in invalidcharacters for char in query):\n",
    "                punct.append(1)\n",
    "            else: \n",
    "                punct.append(0)\n",
    "\n",
    "            if query.islower():\n",
    "                casing.append(0)\n",
    "            else:\n",
    "                casing.append(1)\n",
    "            pbar.update()\n",
    "\n",
    "    allFeatures['punct'] =  punct\n",
    "    allFeatures['casing'] = casing\n",
    "    \n",
    "    return allFeatures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "3a2433c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4746/4746 [00:00<00:00, 215474.35it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>class</th>\n",
       "      <th>punct</th>\n",
       "      <th>casing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US civil war causes</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>scooter brands</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>scooter brands reliable</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>scooter</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>scooter cheap</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4741</th>\n",
       "      <td>House of dreams</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4742</th>\n",
       "      <td>When did Desmond doss get married</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4743</th>\n",
       "      <td>H</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4744</th>\n",
       "      <td>find fact about dog</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4745</th>\n",
       "      <td>kid</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4746 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  query  class  punct  casing\n",
       "0                   US civil war causes      0      0       1\n",
       "1                        scooter brands      0      0       0\n",
       "2               scooter brands reliable      0      0       0\n",
       "3                               scooter      0      0       0\n",
       "4                         scooter cheap      0      0       0\n",
       "...                                 ...    ...    ...     ...\n",
       "4741                    House of dreams      1      0       1\n",
       "4742  When did Desmond doss get married      1      0       1\n",
       "4743                                  H      1      0       1\n",
       "4744                find fact about dog      1      0       0\n",
       "4745                                kid      1      0       0\n",
       "\n",
       "[4746 rows x 4 columns]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Punct_Spell(queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c249fc",
   "metadata": {},
   "source": [
    "## Concreteness "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "4eba5c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def absConcFeat(queries):\n",
    "    \n",
    "    word_concreteness = pickle.load( open( \"data/concreteness/word_concreteness.p\", \"rb\" ) )\n",
    "    word_concreteness['word']=word_concreteness['word'].str.lower() \n",
    "\n",
    "    aw = word_concreteness[word_concreteness['label']=='abstract']\n",
    "    cw = word_concreteness[word_concreteness['label']=='concrete']\n",
    "\n",
    "    abW = []\n",
    "    coW = []\n",
    "    for w_a in aw['word']:\n",
    "        abW.append(w_a)\n",
    "    for w_c in cw['word']:\n",
    "        coW.append(w_c)\n",
    "\n",
    "    absrtCount = []\n",
    "    concCount = []\n",
    "    with tqdm(total=len(queries)) as pbar:\n",
    "        for query in queries:\n",
    "\n",
    "            a_countWord = 0\n",
    "            c_countWord = 0\n",
    "            wordCount = 0\n",
    "            for word in query.split(' '):\n",
    "                word.lower()\n",
    "                wordCount +=1\n",
    "                if word in abW:\n",
    "                    a_countWord +=1\n",
    "                if word in coW:\n",
    "                    c_countWord +=1\n",
    "\n",
    "            absrtCount.append(a_countWord/wordCount)\n",
    "            concCount.append(c_countWord/wordCount)\n",
    "            pbar.update()\n",
    "\n",
    "    allFeatures['ratioAbs'] = absrtCount\n",
    "    allFeatures['ratioConc'] = concCount\n",
    "\n",
    "    return allFeatures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "8a813be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4746/4746 [00:04<00:00, 951.25it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>class</th>\n",
       "      <th>punct</th>\n",
       "      <th>casing</th>\n",
       "      <th>ratioAbs</th>\n",
       "      <th>ratioConc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US civil war causes</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>scooter brands</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>scooter brands reliable</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>scooter</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>scooter cheap</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4741</th>\n",
       "      <td>House of dreams</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4742</th>\n",
       "      <td>When did Desmond doss get married</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4743</th>\n",
       "      <td>H</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4744</th>\n",
       "      <td>find fact about dog</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4745</th>\n",
       "      <td>kid</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4746 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  query  class  punct  casing  ratioAbs  \\\n",
       "0                   US civil war causes      0      0       1  0.250000   \n",
       "1                        scooter brands      0      0       0  0.000000   \n",
       "2               scooter brands reliable      0      0       0  0.333333   \n",
       "3                               scooter      0      0       0  0.000000   \n",
       "4                         scooter cheap      0      0       0  0.500000   \n",
       "...                                 ...    ...    ...     ...       ...   \n",
       "4741                    House of dreams      1      0       1  0.333333   \n",
       "4742  When did Desmond doss get married      1      0       1  0.500000   \n",
       "4743                                  H      1      0       1  0.000000   \n",
       "4744                find fact about dog      1      0       0  0.750000   \n",
       "4745                                kid      1      0       0  0.000000   \n",
       "\n",
       "      ratioConc  \n",
       "0      0.250000  \n",
       "1      0.500000  \n",
       "2      0.333333  \n",
       "3      1.000000  \n",
       "4      0.500000  \n",
       "...         ...  \n",
       "4741   0.000000  \n",
       "4742   0.000000  \n",
       "4743   0.000000  \n",
       "4744   0.250000  \n",
       "4745   1.000000  \n",
       "\n",
       "[4746 rows x 6 columns]"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "absConcFeat(queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f09f99",
   "metadata": {},
   "source": [
    "## LingFeat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df275bae",
   "metadata": {},
   "source": [
    "Later: Rerurn the ling featcode, all of them, get the entire dataframe then one can extrat what they need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "d887be6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ling_feat(queries): #--- this query_list parameter is for fn synstax, it won't be as the feat are extracted\n",
    "\n",
    "    #-- queries and extracted lingFeat  \n",
    "    lingFeat_data = pd.read_csv('Data/castsventrecSQS_All_lingFeat_unstructured_new.csv') \n",
    "\n",
    "    # The following function extracts transform the key of dictonaries into the columns of a \n",
    "    # dataframe and their corresponding values into their corresponding entries\n",
    "\n",
    "    def feat_extract(dataName, featName):\n",
    "        \"\"\" \n",
    "        Steps:\n",
    "        1. Get the keys of a dict to be used as columns in this dataframe.\n",
    "        2. Initially the dictionally are stings. eval() and .replace() are used to convert the str into a dict\n",
    "\n",
    "        \"\"\"\n",
    "        cols = eval(dataName[featName][0].replace(\"'\", \"\\\"\"))\n",
    "        df_tot = pd.DataFrame(columns = list(cols.keys()))\n",
    "        for i in range(len(dataName)):\n",
    "            f = eval(dataName[featName][i].replace(\"'\", \"\\\"\"))\n",
    "            val = np.array(list(f.values())).reshape(-1,1).T # reshape the dict value to become the column entries\n",
    "            df = pd.DataFrame(data = val, columns = list(f.keys()))\n",
    "            df_tot = pd.concat([df_tot, df])\n",
    "\n",
    "        return df_tot\n",
    "\n",
    "    # preprocess\n",
    "    preprocess = feat_extract(lingFeat_data,'preprocess')\n",
    "    # Discourse (Disco)\n",
    "    EntityDensityF = feat_extract(lingFeat_data,'EnDF_')\n",
    "    EntityGridF = feat_extract(lingFeat_data,'EnGF_')\n",
    "    # Syntactic (Synta)\n",
    "    PhrasalF = feat_extract(lingFeat_data,'PhrF_')\n",
    "    TreeStructureF = feat_extract(lingFeat_data,'TrSF_')\n",
    "    PartOfSpeechF = feat_extract(lingFeat_data,'POSF_')\n",
    "    # Lexico Semantic (LxSem)\n",
    "    TypeTokenRatioF = feat_extract(lingFeat_data,'TTRF_')\n",
    "    VariationRatioF = feat_extract(lingFeat_data,'VarF_')\n",
    "    PsycholinguisticF = feat_extract(lingFeat_data,'PsyF_')\n",
    "    WordFamiliarityF = feat_extract(lingFeat_data,'WorF_')\n",
    "    # Shallow Traditional (ShTra)\n",
    "    ShallowF = feat_extract(lingFeat_data,'ShaF_')\n",
    "    TraditionalFormulas = feat_extract(lingFeat_data,'TraF_')\n",
    "\n",
    "    allLingFeat = pd.concat([preprocess, \n",
    "                        EntityDensityF, \n",
    "                        EntityGridF, \n",
    "                        PhrasalF, \n",
    "                        TreeStructureF, \n",
    "                        PartOfSpeechF, \n",
    "                        TypeTokenRatioF, \n",
    "                        VariationRatioF, \n",
    "                        PsycholinguisticF, \n",
    "                        WordFamiliarityF, \n",
    "                        ShallowF, \n",
    "                        TraditionalFormulas], axis=1) \n",
    "#     allFeatures = pd.concat([allFeatures, allLingFeat], axis=1)\n",
    "    \n",
    "    return allLingFeat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "68087cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "allLingFeat = ling_feat(queries)\n",
    "allLingFeat.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "8e414ce4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_token</th>\n",
       "      <th>n_sent</th>\n",
       "      <th>to_EntiM_C</th>\n",
       "      <th>as_EntiM_C</th>\n",
       "      <th>at_EntiM_C</th>\n",
       "      <th>to_UEnti_C</th>\n",
       "      <th>as_UEnti_C</th>\n",
       "      <th>at_UEnti_C</th>\n",
       "      <th>ra_SSTo_C</th>\n",
       "      <th>ra_SOTo_C</th>\n",
       "      <th>...</th>\n",
       "      <th>as_Sylla_C</th>\n",
       "      <th>at_Sylla_C</th>\n",
       "      <th>as_Chara_C</th>\n",
       "      <th>at_Chara_C</th>\n",
       "      <th>FleschG_S</th>\n",
       "      <th>AutoRea_S</th>\n",
       "      <th>ColeLia_S</th>\n",
       "      <th>SmogInd_S</th>\n",
       "      <th>Gunning_S</th>\n",
       "      <th>LinseaW_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.890000</td>\n",
       "      <td>-1.910</td>\n",
       "      <td>-15.803568</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.5</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>-15.005000</td>\n",
       "      <td>-25.455</td>\n",
       "      <td>-15.804156</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>-0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5.250000</td>\n",
       "      <td>-14.810000</td>\n",
       "      <td>-25.270</td>\n",
       "      <td>-15.803568</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>-15.200000</td>\n",
       "      <td>-25.640</td>\n",
       "      <td>-15.804744</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>-15.005000</td>\n",
       "      <td>-25.455</td>\n",
       "      <td>-15.804156</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>-0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4741</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>6.5</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>-15.005000</td>\n",
       "      <td>-25.455</td>\n",
       "      <td>-15.804156</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>-0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4742</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>-0.739286</td>\n",
       "      <td>-1.355</td>\n",
       "      <td>-15.801804</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4743</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-15.395000</td>\n",
       "      <td>-25.825</td>\n",
       "      <td>-15.805332</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.25</td>\n",
       "      <td>-0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4744</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>-2.815000</td>\n",
       "      <td>-6.397</td>\n",
       "      <td>-15.802980</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4745</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>-15.200000</td>\n",
       "      <td>-25.640</td>\n",
       "      <td>-15.804744</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-0.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4746 rows × 225 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     n_token n_sent  to_EntiM_C  as_EntiM_C  at_EntiM_C  to_UEnti_C  \\\n",
       "0          4      2         1.0         0.5    0.250000         1.0   \n",
       "1          3      2         0.0         0.0    0.000000         0.0   \n",
       "2          4      2         0.0         0.0    0.000000         0.0   \n",
       "3          2      2         0.0         0.0    0.000000         0.0   \n",
       "4          3      2         0.0         0.0    0.000000         0.0   \n",
       "...      ...    ...         ...         ...         ...         ...   \n",
       "4741       3      2         1.0         0.5    0.333333         1.0   \n",
       "4742       7      2         1.0         0.5    0.142857         1.0   \n",
       "4743       1      2         0.0         0.0    0.000000         0.0   \n",
       "4744       5      2         0.0         0.0    0.000000         0.0   \n",
       "4745       2      2         0.0         0.0    0.000000         0.0   \n",
       "\n",
       "      as_UEnti_C  at_UEnti_C  ra_SSTo_C  ra_SOTo_C  ...  as_Sylla_C  \\\n",
       "0            0.5    0.250000        0.0        0.0  ...         2.0   \n",
       "1            0.0    0.000000        0.0        0.0  ...         1.5   \n",
       "2            0.0    0.000000        0.0        0.0  ...         2.5   \n",
       "3            0.0    0.000000        NaN        NaN  ...         1.0   \n",
       "4            0.0    0.000000        0.0        0.0  ...         1.5   \n",
       "...          ...         ...        ...        ...  ...         ...   \n",
       "4741         0.5    0.333333        0.0        0.0  ...         1.0   \n",
       "4742         0.5    0.142857        0.0        0.0  ...         4.0   \n",
       "4743         0.0    0.000000        NaN        NaN  ...         0.0   \n",
       "4744         0.0    0.000000        0.0        0.0  ...         2.5   \n",
       "4745         0.0    0.000000        NaN        NaN  ...         0.5   \n",
       "\n",
       "      at_Sylla_C  as_Chara_C  at_Chara_C  FleschG_S  AutoRea_S  ColeLia_S  \\\n",
       "0       1.000000         8.0    4.000000   2.890000     -1.910 -15.803568   \n",
       "1       1.000000         6.5    4.333333 -15.005000    -25.455 -15.804156   \n",
       "2       1.250000        10.5    5.250000 -14.810000    -25.270 -15.803568   \n",
       "3       1.000000         3.5    3.500000 -15.200000    -25.640 -15.804744   \n",
       "4       1.000000         6.0    4.000000 -15.005000    -25.455 -15.804156   \n",
       "...          ...         ...         ...        ...        ...        ...   \n",
       "4741    0.666667         6.5    4.333333 -15.005000    -25.455 -15.804156   \n",
       "4742    1.142857        14.0    4.000000  -0.739286     -1.355 -15.801804   \n",
       "4743    0.000000         0.5    1.000000 -15.395000    -25.825 -15.805332   \n",
       "4744    1.000000         8.0    3.200000  -2.815000     -6.397 -15.802980   \n",
       "4745    0.500000         1.5    1.500000 -15.200000    -25.640 -15.804744   \n",
       "\n",
       "      SmogInd_S  Gunning_S  LinseaW_S  \n",
       "0      1.414214      -0.50       0.00  \n",
       "1      0.000000      -0.75      -0.25  \n",
       "2      0.000000      -0.50       0.00  \n",
       "3      0.000000      -1.00      -0.50  \n",
       "4      0.000000      -0.75      -0.25  \n",
       "...         ...        ...        ...  \n",
       "4741   0.000000      -0.75      -0.25  \n",
       "4742   1.414214       0.25       0.75  \n",
       "4743   0.000000      -1.25      -0.75  \n",
       "4744   1.000000      -0.25       0.25  \n",
       "4745   0.000000      -1.00      -0.50  \n",
       "\n",
       "[4746 rows x 225 columns]"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allLingFeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "5c0c900a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>class</th>\n",
       "      <th>punct</th>\n",
       "      <th>casing</th>\n",
       "      <th>ratioAbs</th>\n",
       "      <th>ratioConc</th>\n",
       "      <th>n_token</th>\n",
       "      <th>n_sent</th>\n",
       "      <th>to_EntiM_C</th>\n",
       "      <th>as_EntiM_C</th>\n",
       "      <th>...</th>\n",
       "      <th>as_Sylla_C</th>\n",
       "      <th>at_Sylla_C</th>\n",
       "      <th>as_Chara_C</th>\n",
       "      <th>at_Chara_C</th>\n",
       "      <th>FleschG_S</th>\n",
       "      <th>AutoRea_S</th>\n",
       "      <th>ColeLia_S</th>\n",
       "      <th>SmogInd_S</th>\n",
       "      <th>Gunning_S</th>\n",
       "      <th>LinseaW_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US civil war causes</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.890000</td>\n",
       "      <td>-1.910</td>\n",
       "      <td>-15.803568</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>scooter brands</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.5</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>-15.005000</td>\n",
       "      <td>-25.455</td>\n",
       "      <td>-15.804156</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>-0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>scooter brands reliable</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5.250000</td>\n",
       "      <td>-14.810000</td>\n",
       "      <td>-25.270</td>\n",
       "      <td>-15.803568</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>scooter</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>-15.200000</td>\n",
       "      <td>-25.640</td>\n",
       "      <td>-15.804744</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>scooter cheap</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>-15.005000</td>\n",
       "      <td>-25.455</td>\n",
       "      <td>-15.804156</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>-0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4741</th>\n",
       "      <td>House of dreams</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>6.5</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>-15.005000</td>\n",
       "      <td>-25.455</td>\n",
       "      <td>-15.804156</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>-0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4742</th>\n",
       "      <td>When did Desmond doss get married</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>-0.739286</td>\n",
       "      <td>-1.355</td>\n",
       "      <td>-15.801804</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4743</th>\n",
       "      <td>H</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-15.395000</td>\n",
       "      <td>-25.825</td>\n",
       "      <td>-15.805332</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.25</td>\n",
       "      <td>-0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4744</th>\n",
       "      <td>find fact about dog</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>-2.815000</td>\n",
       "      <td>-6.397</td>\n",
       "      <td>-15.802980</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4745</th>\n",
       "      <td>kid</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>-15.200000</td>\n",
       "      <td>-25.640</td>\n",
       "      <td>-15.804744</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-0.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4746 rows × 231 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  query  class  punct  casing  ratioAbs  \\\n",
       "0                   US civil war causes      0      0       1  0.250000   \n",
       "1                        scooter brands      0      0       0  0.000000   \n",
       "2               scooter brands reliable      0      0       0  0.333333   \n",
       "3                               scooter      0      0       0  0.000000   \n",
       "4                         scooter cheap      0      0       0  0.500000   \n",
       "...                                 ...    ...    ...     ...       ...   \n",
       "4741                    House of dreams      1      0       1  0.333333   \n",
       "4742  When did Desmond doss get married      1      0       1  0.500000   \n",
       "4743                                  H      1      0       1  0.000000   \n",
       "4744                find fact about dog      1      0       0  0.750000   \n",
       "4745                                kid      1      0       0  0.000000   \n",
       "\n",
       "      ratioConc n_token n_sent  to_EntiM_C  as_EntiM_C  ...  as_Sylla_C  \\\n",
       "0      0.250000       4      2         1.0         0.5  ...         2.0   \n",
       "1      0.500000       3      2         0.0         0.0  ...         1.5   \n",
       "2      0.333333       4      2         0.0         0.0  ...         2.5   \n",
       "3      1.000000       2      2         0.0         0.0  ...         1.0   \n",
       "4      0.500000       3      2         0.0         0.0  ...         1.5   \n",
       "...         ...     ...    ...         ...         ...  ...         ...   \n",
       "4741   0.000000       3      2         1.0         0.5  ...         1.0   \n",
       "4742   0.000000       7      2         1.0         0.5  ...         4.0   \n",
       "4743   0.000000       1      2         0.0         0.0  ...         0.0   \n",
       "4744   0.250000       5      2         0.0         0.0  ...         2.5   \n",
       "4745   1.000000       2      2         0.0         0.0  ...         0.5   \n",
       "\n",
       "      at_Sylla_C  as_Chara_C  at_Chara_C  FleschG_S  AutoRea_S  ColeLia_S  \\\n",
       "0       1.000000         8.0    4.000000   2.890000     -1.910 -15.803568   \n",
       "1       1.000000         6.5    4.333333 -15.005000    -25.455 -15.804156   \n",
       "2       1.250000        10.5    5.250000 -14.810000    -25.270 -15.803568   \n",
       "3       1.000000         3.5    3.500000 -15.200000    -25.640 -15.804744   \n",
       "4       1.000000         6.0    4.000000 -15.005000    -25.455 -15.804156   \n",
       "...          ...         ...         ...        ...        ...        ...   \n",
       "4741    0.666667         6.5    4.333333 -15.005000    -25.455 -15.804156   \n",
       "4742    1.142857        14.0    4.000000  -0.739286     -1.355 -15.801804   \n",
       "4743    0.000000         0.5    1.000000 -15.395000    -25.825 -15.805332   \n",
       "4744    1.000000         8.0    3.200000  -2.815000     -6.397 -15.802980   \n",
       "4745    0.500000         1.5    1.500000 -15.200000    -25.640 -15.804744   \n",
       "\n",
       "      SmogInd_S  Gunning_S  LinseaW_S  \n",
       "0      1.414214      -0.50       0.00  \n",
       "1      0.000000      -0.75      -0.25  \n",
       "2      0.000000      -0.50       0.00  \n",
       "3      0.000000      -1.00      -0.50  \n",
       "4      0.000000      -0.75      -0.25  \n",
       "...         ...        ...        ...  \n",
       "4741   0.000000      -0.75      -0.25  \n",
       "4742   1.414214       0.25       0.75  \n",
       "4743   0.000000      -1.25      -0.75  \n",
       "4744   1.000000      -0.25       0.25  \n",
       "4745   0.000000      -1.00      -0.50  \n",
       "\n",
       "[4746 rows x 231 columns]"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allFeatures = pd.concat([allFeatures, allLingFeat], axis=1)\n",
    "allFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfa11d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6151d015",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6560b2e0",
   "metadata": {},
   "source": [
    "# Test a .py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "122b6ea4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'featExtractMod'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-244-d0bf18af63a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mfeatExtractMod\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'featExtractMod'"
     ]
    }
   ],
   "source": [
    "import featExtractMod as fEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "e7226c9f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fEM' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-246-5e6412b02003>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfEM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabsConcFeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'fEM' is not defined"
     ]
    }
   ],
   "source": [
    "fEM.absConcFeat(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf97a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- NOT COMPLETED ---------------------------\n",
    "\n",
    "def drop_duplicate(query):\n",
    "    \n",
    "    duplicated_columns=query.columns.duplicated()\n",
    "    \n",
    "    new_df=query.loc[:, ~duplicated_columns]\n",
    "    \n",
    "    return new_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
