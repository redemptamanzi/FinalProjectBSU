{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "861f0e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import string\n",
    "import pickle\n",
    "import textstat\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62cf09fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from langdetect import detect\n",
    "from lingfeat import extractor #from lingfeatBASE.lingfeat import extractor\n",
    "from spellchecker import SpellChecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11724103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US civil war causes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>scooter brands</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>scooter brands reliable</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>scooter</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>scooter cheap</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4741</th>\n",
       "      <td>House of dreams</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4742</th>\n",
       "      <td>When did Desmond doss get married</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4743</th>\n",
       "      <td>H</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4744</th>\n",
       "      <td>find fact about dog</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4745</th>\n",
       "      <td>kid</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4746 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  query  class\n",
       "0                   US civil war causes      0\n",
       "1                        scooter brands      0\n",
       "2               scooter brands reliable      0\n",
       "3                               scooter      0\n",
       "4                         scooter cheap      0\n",
       "...                                 ...    ...\n",
       "4741                    House of dreams      1\n",
       "4742  When did Desmond doss get married      1\n",
       "4743                                  H      1\n",
       "4744                find fact about dog      1\n",
       "4745                                kid      1\n",
       "\n",
       "[4746 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_pickle(\"Data/AllQueries4746.p\") \n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4128e223",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_queries = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc3c9a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lingFeatExtract(queries):\n",
    "    \n",
    "    all_queries = queries\n",
    "    \n",
    "    # Pass the text into an extractor\n",
    "    all_queries['extract'] = ''\n",
    "    for i in range(len(all_queries)):\n",
    "        all_queries['extract'][i] = extractor.pass_text(str(all_queries['query'][i]))\n",
    "        \n",
    "    # -- Discourse Feat ---\n",
    "    \n",
    "    # Extract Entity Density Features (EnDF_)\n",
    "    all_queries['EnDF_'] = ''\n",
    "    for i in range(len(all_queries)):\n",
    "        all_queries['EnDF_'][i] = all_queries['extract'][i].preprocess()\n",
    "        \n",
    "    #  Extract entity Grid Features (EnGF_)\n",
    "    EnGF_Def = {'ra_SSToT_C':0,'ra_SOToT_C':0,'ra_SXToT_C':0,'ra_SNToT_C':0,'ra_OSToT_C':0,'ra_OOToT_C':0,'ra_OXToT_C':0,'ra_ONToT_C':0,'ra_XSToT_C':0,'ra_XOToT_C':0,'ra_XXToT_C':0,'ra_XNToT_C':0,'ra_NSToT_C':0,'ra_NOToT_C':0,'ra_NXToT_C':0,'ra_NNToT_C':0,'LoCohPA_S':0,'LoCohPW_S':0,'LoCohPU_S':0,'LoCoDPA_S':0,'LoCoDPW_S':0,'LoCoDPU_S':0}\n",
    "    all_queries['EnGF_'] = ''\n",
    "    for i in range(len(all_queries)):\n",
    "        try:\n",
    "            all_queries['EnGF_'][i] = all_queries['extract'][i].EnGF_()\n",
    "        except:\n",
    "            all_queries['EnGF_'][i] = EnGF_Def\n",
    "            \n",
    "    # ----- Syntactic -----\n",
    "            \n",
    "    # Extract Phrasal Features  (PhrF_)      \n",
    "    all_queries['PhrF_'] = ''\n",
    "    for i in range(len(all_queries)):\n",
    "        all_queries['PhrF_'][i] = all_queries['extract'][i].PhrF_()\n",
    "        \n",
    "    # Extract Tree Structure Features (TrSF_)\n",
    "    all_queries['TrSF_'] = ''\n",
    "    for i in range(len(all_queries)):\n",
    "        all_queries['TrSF_'][i] = all_queries['extract'][i].TrSF_()\n",
    "    \n",
    "    # Extract Part-of-Speech Features (POSF_)\n",
    "    all_queries['POSF_'] = ''\n",
    "    for i in range(len(all_queries)):\n",
    "        all_queries['POSF_'][i] = all_queries['extract'][i].POSF_()\n",
    "    \n",
    "    # ----- Lexico Semantic ------\n",
    "    \n",
    "    # Extract Variation Ratio Features (VarF_)\n",
    "    all_queries['VarF_'] = ''\n",
    "    for i in range(len(all_queries)):\n",
    "        all_queries['VarF_'][i] = all_queries['extract'][i].VarF_()\n",
    "    \n",
    "    # Extract Type Token Ratio Features (TTRF_)\n",
    "    TTRF_def = {'SimpTTR_S':1, 'CorrTTR_S':1, 'BiLoTTR_S':0, 'UberTTR_S':0, 'MTLDTTR_S':0.72}\n",
    "    all_queries['TTRF_'] = ''\n",
    "    for i in range(len(all_queries)):\n",
    "        try:\n",
    "            all_queries['TTRF_'][i] = all_queries['extract'][i].TTRF_()\n",
    "        except:\n",
    "            all_queries['TTRF_'][i] = TTRF_def\n",
    "\n",
    "    # Extract Psycholinguistic Features (PsyF_)\n",
    "    all_queries['PsyF_'] = ''\n",
    "    for i in range(len(all_queries)):\n",
    "        all_queries['PsyF_'][i] = all_queries['extract'][i].PsyF_()\n",
    "    \n",
    "    # Extract Word Familiarity (WorF_)\n",
    "    all_queries['WorF_'] = ''\n",
    "    for i in range(len(all_queries)):\n",
    "        all_queries['WorF_'][i] = all_queries['extract'][i].WorF_()\n",
    "    \n",
    "    # ----- Shallow Traditional -----\n",
    "    \n",
    "    # Extract Shallow Features (ShaF_)\n",
    "    all_queries['ShaF_'] = ''\n",
    "    for i in range(len(all_queries)):\n",
    "        all_queries['ShaF_'][i] = all_queries['extract'][i].ShaF_()\n",
    "    \n",
    "    # Extract Traditional Formulas (TraF_)\n",
    "    all_queries['TraF_'] = ''\n",
    "    for i in range(len(all_queries)):\n",
    "        all_queries['TraF_'][i] = all_queries['extract'][i].TraF_()\n",
    "\n",
    "    return all_queries\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701760e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_queries = lingFeatExtract(all_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913e6904",
   "metadata": {},
   "outputs": [],
   "source": [
    "#***** LINGFEAT (Disco, Synt, LexSem, ShalTrad) **********\n",
    "\n",
    "def lingFeatDictExtract(queries): #--- this query_list parameter is for fn synstax, it won't be as the feat are extracted\n",
    "\n",
    "    #-- queries and extracted lingFeat  \n",
    "    lingFeat_data = pd.read_csv('../Data/castsventrecSQS_All_lingFeat_unstructured_new.csv') \n",
    "\n",
    "    # The following function extracts transform the key of dictonaries into the columns of a \n",
    "    # dataframe and their corresponding values into their corresponding entries\n",
    "\n",
    "    def feat_extract(dataName, featName):\n",
    "        \"\"\" \n",
    "        Steps:\n",
    "        1. Get the keys of a dict to be used as columns in this dataframe.\n",
    "        2. Initially the dictionally are stings. eval() and .replace() are used to convert the str into a dict\n",
    "\n",
    "        \"\"\"\n",
    "        cols = eval(dataName[featName][0].replace(\"'\", \"\\\"\"))\n",
    "        df_tot = pd.DataFrame(columns = list(cols.keys()))\n",
    "        for i in range(len(dataName)):\n",
    "            f = eval(dataName[featName][i].replace(\"'\", \"\\\"\"))\n",
    "            val = np.array(list(f.values())).reshape(-1,1).T # reshape the dict value to become the column entries\n",
    "            df = pd.DataFrame(data = val, columns = list(f.keys()))\n",
    "            df_tot = pd.concat([df_tot, df])\n",
    "\n",
    "        return df_tot\n",
    "\n",
    "    # preprocess\n",
    "    preprocess = feat_extract(lingFeat_data,'preprocess')\n",
    "    # Discourse (Disco)\n",
    "    EntityDensityF = feat_extract(lingFeat_data,'EnDF_')\n",
    "    EntityGridF = feat_extract(lingFeat_data,'EnGF_')\n",
    "    # Syntactic (Synta)\n",
    "    PhrasalF = feat_extract(lingFeat_data,'PhrF_')\n",
    "    TreeStructureF = feat_extract(lingFeat_data,'TrSF_')\n",
    "    PartOfSpeechF = feat_extract(lingFeat_data,'POSF_')\n",
    "    # Lexico Semantic (LxSem)\n",
    "    TypeTokenRatioF = feat_extract(lingFeat_data,'TTRF_')\n",
    "    VariationRatioF = feat_extract(lingFeat_data,'VarF_')\n",
    "    PsycholinguisticF = feat_extract(lingFeat_data,'PsyF_')\n",
    "    WordFamiliarityF = feat_extract(lingFeat_data,'WorF_')\n",
    "    # Shallow Traditional (ShTra)\n",
    "    ShallowF = feat_extract(lingFeat_data,'ShaF_')\n",
    "    TraditionalFormulas = feat_extract(lingFeat_data,'TraF_')\n",
    "\n",
    "    allLingFeat = pd.concat([preprocess, \n",
    "                        EntityDensityF, \n",
    "                        EntityGridF, \n",
    "                        PhrasalF, \n",
    "                        TreeStructureF, \n",
    "                        PartOfSpeechF, \n",
    "                        TypeTokenRatioF, \n",
    "                        VariationRatioF, \n",
    "                        PsycholinguisticF, \n",
    "                        WordFamiliarityF, \n",
    "                        ShallowF, \n",
    "                        TraditionalFormulas], axis=1) \n",
    "#     allFeatures = pd.concat([allFeatures, allLingFeat], axis=1)\n",
    "    \n",
    "    return allLingFeat\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
